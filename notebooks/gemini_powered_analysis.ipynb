{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ AI-Powered FinOps Analysis with Gemini\n",
    "\n",
    "This notebook demonstrates how to use the Gemini 2.5 Pro model to perform a deep, interactive analysis of your cloud cost and usage data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Important: Setup and Authentication\n",
    "\n",
    "Before you begin, make sure you have completed the following steps:\n",
    "\n",
    "1.  **Run the Setup Script**: From your terminal, in the project's root directory, run `bash scripts/setup_gcp_notebook.sh`.\n",
    "2.  **Authenticate to Google Cloud**: Run `gcloud auth application-default login` in your terminal and follow the prompts.\n",
    "3.  **Set Project ID**: Make sure your Google Cloud Project ID is set correctly in the `config.yaml` file or as an environment variable.\n",
    "4.  **Enable Vertex AI API**: Ensure the Vertex AI API is enabled in your Google Cloud project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Step 1: Imports and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from finops_analysis_platform.config_manager import ConfigManager\n",
    "from finops_analysis_platform.data_loader import GCSDataLoader\n",
    "from finops_analysis_platform.gemini_service import initialize_gemini, generate_with_code_execution\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load configuration\n",
    "config_manager = ConfigManager(config_path='config.yaml')\n",
    "gcp_config = config_manager.get('gcp', {})\n",
    "project_id = gcp_config.get('project_id')\n",
    "location = gcp_config.get('location', 'us-central1')\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = initialize_gemini(project_id=project_id, location=location)\n",
    "model_id = 'gemini-2.0-flash-001'\n",
    "\n",
    "print(f\"‚úÖ Gemini client initialized for project '{project_id}' in location '{location}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Load Your Data\n",
    "\n",
    "We'll load the billing and recommendations data from your GCS bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_config = config_manager.get('gcs', {})\n",
    "loader = GCSDataLoader(bucket_name=gcs_config.get('bucket_name'))\n",
    "data = loader.load_all_data()\n",
    "billing_df = data.get('billing')\n",
    "recommendations_df = data.get('recommendations')\n",
    "\n",
    "print(\"‚úÖ Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Step 3: Interactive Analysis with Natural Language\n",
    "\n",
    "Now, you can ask questions about your data in plain English. The Gemini model will generate and execute the code to answer your questions.\n",
    "\n",
    "**Example Prompts:**\n",
    "- \"What are the top 10 most expensive services in the billing data?\"\n",
    "- \"Show me a chart of the daily costs for the last 30 days.\"\n",
    "- \"What is the total potential monthly savings from the recommendations data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the top 5 most expensive services in the billing data?\"\n",
    "\n",
    "response = generate_with_code_execution(client, model_id, prompt)\n",
    "\n",
    "# Display the results\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.executable_code:\n",
    "        display(Markdown(f\"**Generated Code:**\\n```python\\n{part.executable_code.code}\\n```\"))\n",
    "    if part.code_execution_result:\n",
    "        display(Markdown(f\"**Execution Result:**\\n```\\n{part.code_execution_result.output}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Step 4: Automated Insight Generation\n",
    "\n",
    "We can also use Gemini to synthesize the findings from our analysis into a high-level summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this effectively, we would first run our CUD and recommendations analysis,\n",
    "# then pass the results to Gemini.\n",
    "\n",
    "# For this example, we'll use a prompt based on the insights we've already gathered.\n",
    "insights_prompt = \"\"\"\n",
    "I have two sets of data: a CUD analysis and a list of cost-saving recommendations.\n",
    "\n",
    "The CUD analysis shows significant potential savings from a mix of 1-year and 3-year CUDs.\n",
    "The cost-saving recommendations show a total potential monthly savings of $49,860.53, with the largest savings coming from deleting unnecessary snapshots and unattached disks.\n",
    "\n",
    "Please generate a short, actionable summary for a CFO, highlighting the key findings and recommending the next steps.\n",
    "\"\"\"\n",
    "\n",
    "summary_response = generate_with_code_execution(client, model_id, insights_prompt)\n",
    "\n",
    "# Display the generated summary\n",
    "for part in summary_response.candidates[0].content.parts:\n",
    "    if part.text:\n",
    "        display(Markdown(part.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
